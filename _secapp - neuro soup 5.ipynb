{
 "metadata": {
  "name": "",
  "signature": "sha256:c44ecd10f6ace41842f9974867a5c2b09cce3f14026641892963a172fb743b67"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "data normalizer ref:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "#For arbitrary date, daily point datastructures, averages points that are non existing\n",
      "from SecNeural.ClassAlignmentSubsystem import DataNormalization\n",
      "import datetime\n",
      "from SecApp.DBOutputClass import SecuFrame\n",
      "initDO = SecuFrame('')\n",
      "\n",
      "timeObjs = initDO.iffo().orderedmap().processFrameList\n",
      "keyOfInterest = 'dependant_question'\n",
      "normConst = datetime.timedelta(minutes = 20 )\n",
      "\n",
      "DataNormalization(timeObjs,keyOfInterest,normConst).normalized_dtokey_dict\n",
      "DataNormalization(timeObjs,keyOfInterest,normConst).normalizedX\n",
      "DataNormalization(timeObjs,keyOfInterest,normConst).normalizedY"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "FULL TEST CLASS"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Neural Algo Parser Selector class "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NeuroResolve(object):\n",
      "    def __init__(self):\n",
      "        NeuroResolve.rawresults = []\n",
      "        \n",
      "        NeuroResolve.pairedResults = {}\n",
      "        \n",
      "        NeuroResolve.byConditionIDs = []\n",
      "        NeuroResolve.byConditionNames = []\n",
      "        NeuroResolve.queryID = None # id that won the final neural query, that will be used to output respective data\n",
      "        self.basicResolver()\n",
      "        \n",
      "       \n",
      "        \n",
      "    def basicResolver(self):\n",
      "        self.getNeuralData()\n",
      "        self.resultpairid()\n",
      "        self.orderresults()\n",
      "        self.assignFullConditionName()\n",
      "        return self\n",
      "        \n",
      "    def getNeuralData(self): # get\n",
      "        \n",
      "        # will probably need to iterate this once we have more data\n",
      "        \n",
      "        #just one to start\n",
      "        NeuroResolve.queryID = NeuroBasicConditions.allPointSelectionIds[0]\n",
      "        tmplst=[]\n",
      "        tmplst.append(NeuroResolve.queryID)\n",
      "        NeuroResolve.rawresults = NeuroTrainer.mynet.getresult(tmplst,NeuroBasicConditions.allConditionIds)\n",
      "        #itterate and compare datasets\n",
      "        \n",
      "        \n",
      "        \n",
      "        return self\n",
      "    \n",
      "    def resultpairid(self): # pair respective to id\n",
      "        NeuroResolve.pairedResults = {}\n",
      "        for i in range(len(NeuroResolve.rawresults)):\n",
      "            NeuroResolve.pairedResults[NeuroBasicConditions.allConditionIds[i]] = NeuroResolve.rawresults[i]\n",
      "        return self\n",
      "    \n",
      "    def orderresults(self): # order by value return Condition ID list\n",
      "        #list\n",
      "        NeuroResolve.byConditionIDs = sorted(NeuroResolve.pairedResults, key=NeuroResolve.pairedResults.get, reverse=True)\n",
      "        return self\n",
      "    \n",
      "    def assignFullConditionName(self):   # ordered by value return Condition Name list\n",
      "        for _id in NeuroResolve.byConditionIDs:\n",
      "            NeuroResolve.byConditionNames.append(NeuroBasicConditions.idLookupCondtion[_id])\n",
      "        return self\n",
      "\n",
      "    \n",
      "class NeuroOutput(object):\n",
      "    def __init__(self):\n",
      "        NeuroOutput.RawTrainerOutput = [] #empty start\n",
      "        NeuroOutput.process_points = {}\n",
      "        NeuroOutput.process_datasets = {}\n",
      "        NeuroOutput.process_conditions = {}\n",
      "        \n",
      "    def basic_get_top(self):\n",
      "        self.outputConditionID = NeuroResolve.byConditionIDs[0]  # the very first in the ordered array\n",
      "        \n",
      "        self.outputConditionConfiguration = NeuroBasicConditions.conditionsConfig[NeuroBasicConditions.idLookupCondtion[self.outputConditionID]]\n",
      "        \n",
      "        #copy configuration of single point\n",
      "        NeuroOutput.process_points[NeuroBasicConditions.idLookupPointSelection[NeuroResolve.queryID]] = NeuroBasicConditions.pointSelectionConfig[NeuroBasicConditions.idLookupPointSelection[NeuroResolve.queryID]]\n",
      "        \n",
      "        NeuroOutput.process_datasets[NeuroBasicConditions.idLookupDataset[self.outputConditionConfiguration['analyze']]] = NeuroBasicConditions.datasetConfig[NeuroBasicConditions.idLookupDataset[self.outputConditionConfiguration['analyze']]]\n",
      "        \n",
      "        NeuroOutput.process_conditions[self.outputConditionConfiguration['analyze']] = [self.outputConditionConfiguration['ID']] # {datasetid:conditionid}\n",
      "        \n",
      "        \n",
      "        \n",
      "        NeuroTrainer.getResult = True # set to get appended output\n",
      "        NeuroTrainer.methodBasicTrain(self) #appends and writes to NeuroOutput.RawTrainerOutput\n",
      "        NeuroTrainer.getResult = False # reset to train mode\n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        print (NeuroOutput.RawTrainerOutput) #x-coords unordered\n",
      "        \n",
      "        return self\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "            \n",
      "from SecNeural.ClassAlignmentSubsystem import DataNormalization\n",
      "import datetime\n",
      "from SecApp.DBOutputClass import SecuFrame\n",
      "\n",
      "\n",
      "class NeuroTrainer(object):\n",
      "    \n",
      "    def __init__(self):\n",
      "        #pass mynet object\n",
      "        NeuroTrainer.mynet = None\n",
      "        NeuroTrainer.getResult = False\n",
      "        \n",
      "        \n",
      "        \n",
      "    def aquiredata(self):\n",
      "        self.initDO = SecuFrame('')\n",
      "        NeuroTrainer.fromDB = self.initDO.iffo().orderedmap().processFrameList\n",
      "                \n",
      "        return self\n",
      "    \n",
      "    def methodBasicTrain(self):\n",
      "        if (NeuroTrainer.getResult):\n",
      "            NeuroTrainer.process_points = NeuroOutput.process_points\n",
      "            NeuroTrainer.process_datasets = NeuroOutput.process_datasets\n",
      "            NeuroTrainer.process_conditions = NeuroOutput.process_conditions\n",
      "        else: # if it is in training mode, iterate through all conditons and combinations\n",
      "            NeuroTrainer.process_points = NeuroBasicConditions.pointSelectionConfig\n",
      "            NeuroTrainer.process_datasets = NeuroBasicConditions.datasetConfig\n",
      "            NeuroTrainer.process_conditions = NeuroBasicConditions.DatasetConditions\n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        for selectionPointVariable in NeuroTrainer.process_points.keys(): # iterate through point sets\n",
      "            \n",
      "            #Normalized points dataset(object)\n",
      "            #print NeuroBasicConditions.pointSelectionConfig[selectionPointVariable][\"NormConstant\"]\n",
      "            #print \"--------------------\"\n",
      "            #print NeuroBasicConditions.pointSelectionConfig[selectionPointVariable]\n",
      "            #print \"--------------------\"\n",
      "            #print NeuroBasicConditions.pointSelectionConfig\n",
      "            \n",
      "            normalizedSelectionPointData = DataNormalization(NeuroTrainer.fromDB,NeuroBasicConditions.pointSelectionConfig[selectionPointVariable][\"pointSelectSet\"],NeuroBasicConditions.pointSelectionConfig[selectionPointVariable][\"NormConstant\"])\n",
      "            normalizedSelectionPointDataID = NeuroBasicConditions.pointSelectionConfig[selectionPointVariable][\"ID\"]\n",
      "            #computed selection points\n",
      "            \n",
      "            NeuroPoints.__init__(self,normalizedSelectionPointDataID,normalizedSelectionPointData.normalizedX,normalizedSelectionPointData.normalizedY)\n",
      "            computedSelectionPoints = NeuroPoints.XpointsofInterest\n",
      "            \n",
      "            #print \"computedSelectionPoints \" + str(computedSelectionPoints)\n",
      "            \n",
      "            for analyzableDatasetVariable in NeuroTrainer.process_datasets.keys(): # iterate through datasets\n",
      "                \n",
      "                #Normalize dataset (object)\n",
      "                normalizedAnalyzableDataset = DataNormalization(NeuroTrainer.fromDB,analyzableDatasetVariable,NeuroBasicConditions.datasetConfig[analyzableDatasetVariable][\"NormConstant\"])\n",
      "                normalizedAnalyzableDatasetID = NeuroBasicConditions.datasetConfig[analyzableDatasetVariable][\"ID\"]\n",
      "                #compute each condition and train neural network\n",
      "                \n",
      "                \n",
      "                NeuroCondSearch.__init__(self, normalizedAnalyzableDataset.normalizedX, normalizedAnalyzableDataset.normalizedY)\n",
      "                \n",
      "                for computeConditionID in NeuroTrainer.process_conditions[normalizedAnalyzableDatasetID]: # returns ids of conditions attached to dataset\n",
      "                    '''\n",
      "                    {datasetID:[conditionid,conditionid]}\n",
      "                    '''\n",
      "                    #initialize conditional search, use id\n",
      "                    NeuroCondSearch.setID(self, computeConditionID)\n",
      "                    \n",
      "                    #print \"computeConditionID \" + str(computeConditionID)\n",
      "                    for xpoint in computedSelectionPoints: # iterate through each point\n",
      "                        bool_result = NeuroCondSearch.runop(self,xpoint) #process point\n",
      "                        \n",
      "                        if (NeuroTrainer.getResult):\n",
      "                            if (bool_result):\n",
      "                                #append resultant to graph output variable\n",
      "                                NeuroOutput.RawTrainerOutput.append((NeuroCondSearch.CursorDataX[0][0],NeuroCondSearch.CursorDataX[1][-1])) #very first x coord\n",
      "\n",
      "                        else: # if in training mode\n",
      "                            if (bool_result):\n",
      "                                #print \"= TRAIN WAS OK; Xpoint:  \" + str(xpoint)  + \"computeConditionID: \" + str(computeConditionID) + \" normalizedAnalyzableDatasetID: \" + str(normalizedAnalyzableDatasetID) + \" normalizedSelectionPointDataID: \" + str(normalizedSelectionPointDataID)\n",
      "                                NeuroTrainer.mynet.trainquery(NeuroBasicConditions.allPointSelectionIds,NeuroBasicConditions.allConditionIds, computeConditionID)\n",
      "\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "from SecApp.DBQuestionClass import SecuQ\n",
      "class NeuroBasicConditions(object):\n",
      "    def __init__(self,key,depVarsLst,indepVarsLst):\n",
      "        self.depVarsLst = depVarsLst\n",
      "        self.indepVarsLst = indepVarsLst\n",
      "        self.key = key\n",
      "        self.initQ = SecuQ(self.key)\n",
      "        '''\n",
      "        available parameters used to construct conditions\n",
      "        '''\n",
      "        #analytics conditions\n",
      "        self.baseconditions = [\"increase\"]\n",
      "        self.pointofinteresttype = [\"localmax\"]\n",
      "        #more to be added\n",
      "        #baseconditions = {\"increase\":1,\"decrease\":2,\"MA14_increase\":3,\"MA14_decrease\":4}\n",
      "        self.phasedeltas = [2,3,4,5,6,7,14,21] #how much data in each segment \n",
      "        self.phaseshifts = [1,2,3,4,5,6,7,14,21] # how much data is shifted from phase ( x coord[date])\n",
      "    \n",
      "        '''\n",
      "        constructed conditions (with different maps for easy access)\n",
      "        '''\n",
      "\n",
      "    \n",
      "        NeuroBasicConditions.conditionsConfig = {} #analysis algo conditions\n",
      "        NeuroBasicConditions.conditionLookupId = {}\n",
      "        NeuroBasicConditions.idLookupCondtion = {}\n",
      "        NeuroBasicConditions.allConditionIds = []\n",
      "        NeuroBasicConditions.DatasetConditions = {}\n",
      "        \n",
      "    \n",
      "    \n",
      "        NeuroBasicConditions.pointSelectionConfig = {} #dependant IDs point selection algo\n",
      "        NeuroBasicConditions.pointSelectionLookupId = {}\n",
      "        NeuroBasicConditions.idLookupPointSelection = {}\n",
      "        NeuroBasicConditions.allPointSelectionIds = []\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "        NeuroBasicConditions.datasetConfig = {} #independantID datasets available\n",
      "        NeuroBasicConditions.datasetLookupId = {}\n",
      "        NeuroBasicConditions.idLookupDataset = {}\n",
      "        NeuroBasicConditions.allDatasetIds = []\n",
      "        \n",
      "    \n",
      "        '''\n",
      "        this holds starting id numbers for configurtation data \n",
      "        '''\n",
      "        ###\n",
      "        self.depIDcount = 300\n",
      "        \n",
      "        self.indepIDcount = 500\n",
      "        \n",
      "        self.condIDcount = 700\n",
      "    \n",
      "        self.buildselectionpointIDs()\n",
      "        self.buildindependantIDs()\n",
      "        self.buildconditions()\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "    \n",
      "    \n",
      "    def getNormConstant(self,varkey):  # for variables only\n",
      "        if (varkey in self.initQ.multipoint.keys()) & (varkey in self.initQ.aggregate.keys()):\n",
      "            #self.varTypes_v2t_dict[varkey] = 'mp_aggre' # multipoint with aggregate data in dailykey, \"keyname\"_aggregate:value\n",
      "            \n",
      "            #self.varTypes_id2t_dict[self.variable_v2id_dict[varkey]] = 'mp_aggre'\n",
      "            raise Exception(\"NO MULTI-AGREGATE VARIABLES (IN ALPHA)\")\n",
      "            return False #breakloop\n",
      "            \n",
      "        if (varkey in self.initQ.aggregate.keys()):\n",
      "            return datetime.timedelta(days = 1 )\n",
      "        \n",
      "        if (varkey in self.initQ.multipoint.keys()):\n",
      "            return datetime.timedelta(minutes = 30 )\n",
      "            \n",
      "        if (varkey in self.initQ.active.keys()):\n",
      "            return datetime.timedelta(days = 1 )\n",
      "  \n",
      "    \n",
      "    \n",
      "    def buildselectionpointIDs(self): #builddependantIDs\n",
      "        for pointselectionalgo in self.pointofinteresttype:\n",
      "            for var in self.depVarsLst:\n",
      "                \n",
      "                builtPointSelectionTmp = str(var) + \"-\" + str(pointselectionalgo)+ \"-\" + str(self.depIDcount)\n",
      "                NeuroBasicConditions.pointSelectionConfig[builtPointSelectionTmp] = {}\n",
      "                NeuroBasicConditions.pointSelectionConfig[builtPointSelectionTmp][\"pointSelectSet\"] = var\n",
      "                NeuroBasicConditions.pointSelectionConfig[builtPointSelectionTmp][\"selection_algo\"] = pointselectionalgo\n",
      "                NeuroBasicConditions.pointSelectionConfig[builtPointSelectionTmp][\"ID\"] = self.depIDcount\n",
      "                NeuroBasicConditions.pointSelectionConfig[builtPointSelectionTmp][\"NormConstant\"] = self.getNormConstant(var)\n",
      "              \n",
      "                NeuroBasicConditions.pointSelectionLookupId[builtPointSelectionTmp] = self.depIDcount\n",
      "            \n",
      "                NeuroBasicConditions.idLookupPointSelection[self.depIDcount] = builtPointSelectionTmp\n",
      "            \n",
      "                NeuroBasicConditions.allPointSelectionIds.append(self.depIDcount)\n",
      "            \n",
      "                self.depIDcount+= 1\n",
      "        return self\n",
      "            \n",
      "                \n",
      "            \n",
      "            \n",
      "    def buildindependantIDs(self): #build analyzable (comparable dataset) ids\n",
      "        for var in self.indepVarsLst:\n",
      "            NeuroBasicConditions.datasetConfig[var] = {}\n",
      "            NeuroBasicConditions.datasetConfig[var][\"ID\"] = self.indepIDcount\n",
      "            NeuroBasicConditions.datasetConfig[var][\"NormConstant\"] = self.getNormConstant(var)\n",
      "            \n",
      "            NeuroBasicConditions.datasetLookupId[var] = self.indepIDcount\n",
      "            \n",
      "            NeuroBasicConditions.idLookupDataset[self.indepIDcount] = var\n",
      "            \n",
      "            NeuroBasicConditions.allDatasetIds.append(self.indepIDcount)\n",
      "            \n",
      "            \n",
      "            self.indepIDcount+=1\n",
      "        return self\n",
      "\n",
      "    \n",
      "    def buildconditions(self): # add [haseshifts]\n",
      "        for var in NeuroBasicConditions.datasetConfig.keys():\n",
      "            currVarID = NeuroBasicConditions.datasetConfig[var][\"ID\"]\n",
      "            NeuroBasicConditions.DatasetConditions[currVarID] = []\n",
      "            \n",
      "            for condition in self.baseconditions:\n",
      "                for delta in self.phasedeltas:\n",
      "                    for shift in self.phaseshifts:\n",
      "                        \n",
      "                        \n",
      "                    \n",
      "                        builtconditiontmp = str(condition) + \"-\" + str(currVarID)+ \"-\" + str(delta)+ \"-\" + str(shift)\n",
      "                    \n",
      "                        \n",
      "                        NeuroBasicConditions.conditionsConfig[builtconditiontmp] = {}\n",
      "                        NeuroBasicConditions.conditionsConfig[builtconditiontmp][\"analyze\"] = currVarID\n",
      "                        NeuroBasicConditions.conditionsConfig[builtconditiontmp]['condition'] = condition\n",
      "                        NeuroBasicConditions.conditionsConfig[builtconditiontmp]['delta'] = delta\n",
      "                        NeuroBasicConditions.conditionsConfig[builtconditiontmp]['shift'] = shift\n",
      "                        NeuroBasicConditions.conditionsConfig[builtconditiontmp]['ID'] = self.condIDcount\n",
      "                        \n",
      "                        \n",
      "                        NeuroBasicConditions.DatasetConditions[currVarID].append(self.condIDcount)\n",
      "                        \n",
      "                        NeuroBasicConditions.idLookupCondtion[self.condIDcount] = builtconditiontmp\n",
      "                    \n",
      "                        NeuroBasicConditions.conditionLookupId[builtconditiontmp] = self.condIDcount\n",
      "                    \n",
      "                        NeuroBasicConditions.allConditionIds.append(self.condIDcount)\n",
      "                    \n",
      "                        self.condIDcount+=1\n",
      "        return self\n",
      "    \n",
      "\n",
      "class NeuroPoints(object):\n",
      "    def __init__(self,ID,datasetX,datasetY):      \n",
      "        self.datasetX = datasetX\n",
      "        self.datasetY = datasetY\n",
      "        self.datasetID = ID\n",
      "        \n",
      "        ## must be initialized before hand\n",
      "        self.PointTypeName = NeuroBasicConditions.idLookupPointSelection[self.datasetID]\n",
      "        self.datasetParams = NeuroBasicConditions.pointSelectionConfig[self.PointTypeName]\n",
      "        \n",
      "        ##class variable\n",
      "        NeuroPoints.XpointsofInterest = None\n",
      "        \n",
      "        self.runop()\n",
      "        \n",
      "        \n",
      "    def runop(self):\n",
      "        '''\n",
      "        These must correspond to the methods available in NeuroBasic Conditions under key\n",
      "        self.pointofinteresttype = [\"localmax\"]\n",
      "        '''\n",
      "        if (self.datasetParams[\"selection_algo\"] == \"localmax\" ):\n",
      "            NeuroPoints.XpointsofInterest = self.FindMaximalpos(self.datasetX,self.datasetY)\n",
      "            return True\n",
      "        \n",
      "        \n",
      "     # finds points of interest in dependant variable (phase points)\n",
      "    def FindMaximalpos(self,aX,aY):\n",
      "        '''\n",
      "        Input aligned:\n",
      "        x array\n",
      "        y array\n",
      "        \n",
      "        Output (X):\n",
      "        array[x_dto ,....]\n",
      "        \n",
      "        '''\n",
      "        maximaposX = []\n",
      "        length = len(aY)\n",
      "        if length >= 2:\n",
      "            if aY[0] > aY[1]:\n",
      "                maximaposX.append(aX[0])\n",
      "    \n",
      "           \n",
      "        if length > 3:\n",
      "            for i in range(1, length-1):     \n",
      "                if aY[i] > aY[i-1] and aY[i] > aY[i+1]:\n",
      "                    maximaposX.append(aX[i])\n",
      "    \n",
      "    \n",
      "        if aY[length-1] > aY[length-2]:\n",
      "            maximaposX.append(aX[length-1])\n",
      "           \n",
      "        #print \"maximaposX \" + str(maximaposX)\n",
      "        return maximaposX\n",
      "    \n",
      "    \n",
      "class NeuroCondSearch(object):\n",
      "    ''' \n",
      "    this class defines all the conditional operations available to be performed on normalized data\n",
      "    \n",
      "    '''\n",
      "\n",
      "    def __init__(self,datasetX,datasetY):\n",
      "        \n",
      "        self.datasetX = datasetX\n",
      "        self.datasetY = datasetY\n",
      "        \n",
      "    \n",
      "    def setID(self,ID): #id is the condition you want to search\n",
      "        #temporary lookup operation\n",
      "        conditionName = NeuroBasicConditions.idLookupCondtion[ID]\n",
      "        #assign constants\n",
      "        self.CursorShift = NeuroBasicConditions.conditionsConfig[conditionName]['shift']\n",
      "        self.CursorDelta = NeuroBasicConditions.conditionsConfig[conditionName]['delta']\n",
      "        #assign method\n",
      "        self.method = NeuroBasicConditions.conditionsConfig[conditionName]['condition']\n",
      "    \n",
      "    def runop(self,XSelectionPoint):\n",
      "        #print \"XSelectionPoint \" + str(XSelectionPoint) \n",
      "        self.XSelectionPoint = XSelectionPoint\n",
      "        \n",
      "        if (self.method == \"increase\"):\n",
      "            return self.Method_increase()\n",
      "    \n",
      "\n",
      "    def single_output(self): #special method for processing with graph output\n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        '''\n",
      "        Methods for processing data, return is always boolean\n",
      "    \n",
      "        '''\n",
      "        \n",
      "    def Method_increase(self):\n",
      "               \n",
      "        #Phase point array\n",
      "        self.error = False # if there is an error anywhere\n",
      "        self.phase_shift_delta_sample_cursor()\n",
      "        return self.sectionincrease()\n",
      "        \n",
      "        '''\n",
      "        processing helpers\n",
      "        '''\n",
      "        \n",
      "    def phase_shift_delta_sample_cursor(self):\n",
      "        '''\n",
      "        Only two sets are computed using this\n",
      "        \n",
      "        index 0 used as the phase point, then delta searches backwards in time\n",
      "        self.CursorX = :\n",
      "        self.CursorY =\n",
      "        array[(x_dto,y)], array[(x_dto,y]\n",
      "        \n",
      "        '''\n",
      "        #shift\n",
      "        \n",
      "        #self.CursorShift\n",
      "        \n",
      "        #delta\n",
      "        #self.CursorDelta\n",
      "        \n",
      "        #phase\n",
      "        #print self.datasetX\n",
      "        #print \"==================================================================\"\n",
      "        #print self.XSelectionPoint\n",
      "        \n",
      "        try:\n",
      "            phaseIndex = self.datasetX.index(self.XSelectionPoint)\n",
      "        except: \n",
      "            '''\n",
      "            Key error pretty sure, if there is an error, \n",
      "            the selection point variable is a multipoint type variable, \n",
      "            therefore if compared to a variable with daily type, their normalization was not the same and \n",
      "            therefore will have points that dont match.\n",
      "            \n",
      "            to fix:\n",
      "            solution 1 (harder): findout if multipoint is being compared to daily type before normalization, \n",
      "            then adjust normalization constant accordingly ( will have problems re-calling data afterwards)\n",
      "            \n",
      "            solution 2:\n",
      "            \n",
      "            \n",
      "            solution 3: (bad/lazy):\n",
      "            ignore it and say FALSE\n",
      "            \n",
      "            \n",
      "            '''\n",
      "            \n",
      "            self.error = True\n",
      "            return self #exit loop\n",
      "        \n",
      "        \n",
      "        \n",
      "        shiftIndex = phaseIndex - self.CursorShift\n",
      "        \n",
      "        x0 = shiftIndex\n",
      "        x1 = shiftIndex - self.CursorDelta\n",
      "        x2 = x1 - self.CursorDelta\n",
      "        delta0X = []\n",
      "        delta0Y = []\n",
      "        delta1X = []\n",
      "        delta1Y = []\n",
      "        \n",
      "        # both sets left to right, forward in time\n",
      "        try:\n",
      "            for i in xrange(x1,x0):\n",
      "                delta0X.append(self.datasetX[i])\n",
      "                delta0Y.append(self.datasetY[i])\n",
      "            for i in xrange(x2,x1):\n",
      "                delta1X.append(self.datasetX[i])\n",
      "                delta1Y.append(self.datasetY[i])\n",
      "        except:\n",
      "            self.error = True\n",
      "            return self #exit loop\n",
      "            \n",
      "        # left to right\n",
      "        NeuroCondSearch.CursorDataY = delta1Y,delta0Y # output Y coords \n",
      "        NeuroCondSearch.CursorDataX = delta1X,delta0X # output Y coords\n",
      "        return self\n",
      "            \n",
      "            \n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "    \n",
      "    def sectionincrease(self): #only for comparing two sets\n",
      "        \n",
      "        '''\n",
      "        input section list[(tuple),(tuple)] \n",
      "        (tuple) = \n",
      "        \n",
      "        output tuple(x_dto,boolean)\n",
      "        \n",
      "        self.Cursor\n",
      "        \n",
      "        '''\n",
      "        #check error processing error level\n",
      "        if (self.error): # if there's an error exit and return point as false to trainer\n",
      "            return False\n",
      "        \n",
      "        #self.CursorData, left to right\n",
      "        #using average of list\n",
      "        av1 = reduce(lambda y1, y2: y1 + y2, NeuroCondSearch.CursorDataY[0]) / len(NeuroCondSearch.CursorDataY[0])\n",
      "        av2 = reduce(lambda y1, y2: y1 + y2, NeuroCondSearch.CursorDataY[1]) / len(NeuroCondSearch.CursorDataY[1])\n",
      "        if (av1<av2): # if left smaller than right, increased forward in time\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "        \n",
      "        \n",
      "    def allincreases(self):\n",
      "        '''\n",
      "        \n",
      "        input:\n",
      "        \n",
      "        \n",
      "        '''\n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "import datetime\n",
      "from SecNeural import nn\n",
      "from SecNeural.ClassAlignmentSubsystem import DataNormalization\n",
      "from SecApp.DBOutputClass import SecuFrame\n",
      "\n",
      "\n",
      "class NeuroBasicAlgo(NeuroBasicConditions,NeuroTrainer,NeuroPoints,NeuroCondSearch,NeuroResolve,NeuroOutput):\n",
      "    '''\n",
      "    ex:\n",
      "    algoConfig = {\"algo_id\" = \"SOME HEX\" , \"algoName\":\"Basic\", \"algoMode\":\"Basic\" \"independantVars\":[\"some var\",\"some var\"]  , \"dependantVars\":[\"some var\",\"some var\"]}\n",
      "    '''\n",
      "    def __init__(self,key,algoConfig):\n",
      "        self.key = key\n",
      "        self.algoConfig = algoConfig\n",
      "        self.parseconfig()\n",
      "        \n",
      "        \n",
      "        #creates conditional id subsystem\n",
      "        NeuroBasicConditions.__init__(self,self.key,self.dependantVars,self.independantVars) ## FINISH initialization\n",
      "        \n",
      "        NeuroTrainer.__init__(self) #init\n",
      "        self.build_neural_net() # pass neural database object to neural trainer\n",
      "        self.train_neural_net()\n",
      "        self.resolve_neural_net()\n",
      "        \n",
      "        \n",
      "    def parseconfig(self):\n",
      "        self.neuroStore = str(self.algoConfig[\"algo_id\"]) + \"_Basic.db\"\n",
      "        self.dependantVars = sorted(self.algoConfig[\"dependantVars\"], key=str.lower)\n",
      "        #independant variables always sorted alphabetically to ensure ID replication\n",
      "        self.independantVars = sorted(self.algoConfig[\"independantVars\"], key=str.lower)\n",
      "        return self\n",
      "        \n",
      "    def build_neural_net(self):\n",
      "        NeuroTrainer.mynet = nn.searchnet() # nn.searchnet(self.neuroStore) deprecated using ':memory:'\n",
      "        NeuroTrainer.mynet.maketables()\n",
      "        ####\n",
      "        '''\n",
      "        self.mynet.generatehiddennode( [   all condition ids for each analyzable dataset   ] , [  all point of interest ids   ] )\n",
      "        \n",
      "        self.mynet.generatehiddennode([dataids['dependant_data'],dataids['independant_data']],allconditionids(phasedeltas))\n",
      "        '''\n",
      "        \n",
      "        NeuroTrainer.mynet.generatehiddennode(NeuroBasicConditions.allPointSelectionIds,NeuroBasicConditions.allConditionIds)\n",
      "        return self\n",
      "           \n",
      "    def train_neural_net(self):\n",
      "        #aquire data\n",
      "        NeuroTrainer.aquiredata(self)\n",
      "        NeuroTrainer.methodBasicTrain(self)\n",
      "        return self    \n",
      "    \n",
      "    def resolve_neural_net(self):\n",
      "        NeuroResolve.__init__(self)\n",
      "        \n",
      "        \n",
      "        #print NeuroResolve.byConditionIDs\n",
      "        \n",
      "        \n",
      "        #print NeuroResolve.byConditionNames\n",
      "            \n",
      "        #print NeuroResolve.pairedResults\n",
      "        \n",
      "        NeuroOutput.__init__(self)\n",
      "        NeuroOutput.basic_get_top(self)\n",
      "        return self\n",
      "        \n",
      " \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime\n",
      "algoConfig ={\"algo_id\" : \"hx0\" , \"algoName\":\"Basic\", \"algoMode\":\"Basic\", \"independantVars\":[\"a\",\"b\"]  , \"dependantVars\":[\"c\",\"d\"]}\n",
      "key = \"\"\n",
      "time1 = datetime.datetime.now()\n",
      "test = NeuroBasicAlgo(key,algoConfig)\n",
      "time2 = datetime.datetime.now()\n",
      "tottime = time2 - time1\n",
      "print \"EXCECUTION TIME: \" + str(tottime)\n",
      "print \"S: \" + str(tottime.seconds) + \" us: \" + str(tottime.microseconds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(1407281400.0, 1407355200.0), (1407627000.0, 1407700800.0)]\n",
        "EXCECUTION TIME: 0:00:32.703000\n",
        "S: 32 us: 703000\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Neural Network Level 1 data retreival"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hx0_Basic.db"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "        NeuroTrainer.process_points = NeuroBasicConditions.pointSelectionConfig\n",
      "        NeuroTrainer.process_datasets = NeuroBasicConditions.datasetConfig\n",
      "        NeuroTrainer.process_conditions = NeuroBasicConditions.DatasetConditions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "##### builder test class\n",
      "\n",
      "'''\n",
      "class testconditionbuilder(NeuroBasicConditions):\n",
      "    def __init__(self):\n",
      "        depVarsLst = ['a','b']\n",
      "        indepVarsLst = ['c','d']\n",
      "        key =  \"\"\n",
      "        NeuroBasicConditions.__init__(self,key,depVarsLst,indepVarsLst)\n",
      "        \n",
      "        \n",
      "test = testconditionbuilder()\n",
      "\n",
      "#test.conditionsConfig\n",
      "#test.baseconditions\n",
      "\n",
      "\n",
      "#test.pointofinteresttype\n",
      "\n",
      "#test.phasedeltas \n",
      "\n",
      "#test.phaseshifts\n",
      "\n",
      "test.conditionsConfig \n",
      "#test.conditionLookupId\n",
      "#test.idLookupCondtion\n",
      "#test.allConditionIds\n",
      "#test.DatasetConditions\n",
      "\n",
      "#test.pointSelectionConfig \n",
      "#test.pointSelectionLookupId\n",
      "#test.idLookupPointSelection\n",
      "#test.allPointSelectionIds\n",
      "\n",
      "#test.datasetConfig \n",
      "#test.datasetLookupId\n",
      "#test.idLookupDataset\n",
      "#test.allDatasetIds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "{'increase-500-14-1': {'ID': 754,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 1},\n",
        " 'increase-500-14-14': {'ID': 761,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 14},\n",
        " 'increase-500-14-2': {'ID': 755,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 2},\n",
        " 'increase-500-14-21': {'ID': 762,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 21},\n",
        " 'increase-500-14-3': {'ID': 756,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 3},\n",
        " 'increase-500-14-4': {'ID': 757,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 4},\n",
        " 'increase-500-14-5': {'ID': 758,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 5},\n",
        " 'increase-500-14-6': {'ID': 759,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 6},\n",
        " 'increase-500-14-7': {'ID': 760,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 7},\n",
        " 'increase-500-2-1': {'ID': 700,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 1},\n",
        " 'increase-500-2-14': {'ID': 707,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 14},\n",
        " 'increase-500-2-2': {'ID': 701,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 2},\n",
        " 'increase-500-2-21': {'ID': 708,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 21},\n",
        " 'increase-500-2-3': {'ID': 702,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 3},\n",
        " 'increase-500-2-4': {'ID': 703,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 4},\n",
        " 'increase-500-2-5': {'ID': 704,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 5},\n",
        " 'increase-500-2-6': {'ID': 705,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 6},\n",
        " 'increase-500-2-7': {'ID': 706,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 7},\n",
        " 'increase-500-21-1': {'ID': 763,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 1},\n",
        " 'increase-500-21-14': {'ID': 770,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 14},\n",
        " 'increase-500-21-2': {'ID': 764,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 2},\n",
        " 'increase-500-21-21': {'ID': 771,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 21},\n",
        " 'increase-500-21-3': {'ID': 765,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 3},\n",
        " 'increase-500-21-4': {'ID': 766,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 4},\n",
        " 'increase-500-21-5': {'ID': 767,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 5},\n",
        " 'increase-500-21-6': {'ID': 768,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 6},\n",
        " 'increase-500-21-7': {'ID': 769,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 7},\n",
        " 'increase-500-3-1': {'ID': 709,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 1},\n",
        " 'increase-500-3-14': {'ID': 716,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 14},\n",
        " 'increase-500-3-2': {'ID': 710,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 2},\n",
        " 'increase-500-3-21': {'ID': 717,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 21},\n",
        " 'increase-500-3-3': {'ID': 711,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 3},\n",
        " 'increase-500-3-4': {'ID': 712,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 4},\n",
        " 'increase-500-3-5': {'ID': 713,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 5},\n",
        " 'increase-500-3-6': {'ID': 714,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 6},\n",
        " 'increase-500-3-7': {'ID': 715,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 7},\n",
        " 'increase-500-4-1': {'ID': 718,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 1},\n",
        " 'increase-500-4-14': {'ID': 725,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 14},\n",
        " 'increase-500-4-2': {'ID': 719,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 2},\n",
        " 'increase-500-4-21': {'ID': 726,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 21},\n",
        " 'increase-500-4-3': {'ID': 720,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 3},\n",
        " 'increase-500-4-4': {'ID': 721,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 4},\n",
        " 'increase-500-4-5': {'ID': 722,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 5},\n",
        " 'increase-500-4-6': {'ID': 723,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 6},\n",
        " 'increase-500-4-7': {'ID': 724,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 7},\n",
        " 'increase-500-5-1': {'ID': 727,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 1},\n",
        " 'increase-500-5-14': {'ID': 734,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 14},\n",
        " 'increase-500-5-2': {'ID': 728,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 2},\n",
        " 'increase-500-5-21': {'ID': 735,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 21},\n",
        " 'increase-500-5-3': {'ID': 729,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 3},\n",
        " 'increase-500-5-4': {'ID': 730,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 4},\n",
        " 'increase-500-5-5': {'ID': 731,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 5},\n",
        " 'increase-500-5-6': {'ID': 732,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 6},\n",
        " 'increase-500-5-7': {'ID': 733,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 7},\n",
        " 'increase-500-6-1': {'ID': 736,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 1},\n",
        " 'increase-500-6-14': {'ID': 743,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 14},\n",
        " 'increase-500-6-2': {'ID': 737,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 2},\n",
        " 'increase-500-6-21': {'ID': 744,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 21},\n",
        " 'increase-500-6-3': {'ID': 738,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 3},\n",
        " 'increase-500-6-4': {'ID': 739,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 4},\n",
        " 'increase-500-6-5': {'ID': 740,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 5},\n",
        " 'increase-500-6-6': {'ID': 741,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 6},\n",
        " 'increase-500-6-7': {'ID': 742,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 7},\n",
        " 'increase-500-7-1': {'ID': 745,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 1},\n",
        " 'increase-500-7-14': {'ID': 752,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 14},\n",
        " 'increase-500-7-2': {'ID': 746,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 2},\n",
        " 'increase-500-7-21': {'ID': 753,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 21},\n",
        " 'increase-500-7-3': {'ID': 747,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 3},\n",
        " 'increase-500-7-4': {'ID': 748,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 4},\n",
        " 'increase-500-7-5': {'ID': 749,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 5},\n",
        " 'increase-500-7-6': {'ID': 750,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 6},\n",
        " 'increase-500-7-7': {'ID': 751,\n",
        "  'analyze': 500,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 7},\n",
        " 'increase-501-14-1': {'ID': 826,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 1},\n",
        " 'increase-501-14-14': {'ID': 833,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 14},\n",
        " 'increase-501-14-2': {'ID': 827,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 2},\n",
        " 'increase-501-14-21': {'ID': 834,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 21},\n",
        " 'increase-501-14-3': {'ID': 828,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 3},\n",
        " 'increase-501-14-4': {'ID': 829,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 4},\n",
        " 'increase-501-14-5': {'ID': 830,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 5},\n",
        " 'increase-501-14-6': {'ID': 831,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 6},\n",
        " 'increase-501-14-7': {'ID': 832,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 14,\n",
        "  'shift': 7},\n",
        " 'increase-501-2-1': {'ID': 772,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 1},\n",
        " 'increase-501-2-14': {'ID': 779,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 14},\n",
        " 'increase-501-2-2': {'ID': 773,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 2},\n",
        " 'increase-501-2-21': {'ID': 780,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 21},\n",
        " 'increase-501-2-3': {'ID': 774,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 3},\n",
        " 'increase-501-2-4': {'ID': 775,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 4},\n",
        " 'increase-501-2-5': {'ID': 776,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 5},\n",
        " 'increase-501-2-6': {'ID': 777,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 6},\n",
        " 'increase-501-2-7': {'ID': 778,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 2,\n",
        "  'shift': 7},\n",
        " 'increase-501-21-1': {'ID': 835,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 1},\n",
        " 'increase-501-21-14': {'ID': 842,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 14},\n",
        " 'increase-501-21-2': {'ID': 836,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 2},\n",
        " 'increase-501-21-21': {'ID': 843,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 21},\n",
        " 'increase-501-21-3': {'ID': 837,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 3},\n",
        " 'increase-501-21-4': {'ID': 838,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 4},\n",
        " 'increase-501-21-5': {'ID': 839,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 5},\n",
        " 'increase-501-21-6': {'ID': 840,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 6},\n",
        " 'increase-501-21-7': {'ID': 841,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 21,\n",
        "  'shift': 7},\n",
        " 'increase-501-3-1': {'ID': 781,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 1},\n",
        " 'increase-501-3-14': {'ID': 788,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 14},\n",
        " 'increase-501-3-2': {'ID': 782,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 2},\n",
        " 'increase-501-3-21': {'ID': 789,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 21},\n",
        " 'increase-501-3-3': {'ID': 783,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 3},\n",
        " 'increase-501-3-4': {'ID': 784,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 4},\n",
        " 'increase-501-3-5': {'ID': 785,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 5},\n",
        " 'increase-501-3-6': {'ID': 786,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 6},\n",
        " 'increase-501-3-7': {'ID': 787,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 3,\n",
        "  'shift': 7},\n",
        " 'increase-501-4-1': {'ID': 790,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 1},\n",
        " 'increase-501-4-14': {'ID': 797,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 14},\n",
        " 'increase-501-4-2': {'ID': 791,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 2},\n",
        " 'increase-501-4-21': {'ID': 798,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 21},\n",
        " 'increase-501-4-3': {'ID': 792,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 3},\n",
        " 'increase-501-4-4': {'ID': 793,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 4},\n",
        " 'increase-501-4-5': {'ID': 794,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 5},\n",
        " 'increase-501-4-6': {'ID': 795,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 6},\n",
        " 'increase-501-4-7': {'ID': 796,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 4,\n",
        "  'shift': 7},\n",
        " 'increase-501-5-1': {'ID': 799,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 1},\n",
        " 'increase-501-5-14': {'ID': 806,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 14},\n",
        " 'increase-501-5-2': {'ID': 800,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 2},\n",
        " 'increase-501-5-21': {'ID': 807,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 21},\n",
        " 'increase-501-5-3': {'ID': 801,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 3},\n",
        " 'increase-501-5-4': {'ID': 802,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 4},\n",
        " 'increase-501-5-5': {'ID': 803,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 5},\n",
        " 'increase-501-5-6': {'ID': 804,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 6},\n",
        " 'increase-501-5-7': {'ID': 805,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 5,\n",
        "  'shift': 7},\n",
        " 'increase-501-6-1': {'ID': 808,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 1},\n",
        " 'increase-501-6-14': {'ID': 815,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 14},\n",
        " 'increase-501-6-2': {'ID': 809,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 2},\n",
        " 'increase-501-6-21': {'ID': 816,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 21},\n",
        " 'increase-501-6-3': {'ID': 810,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 3},\n",
        " 'increase-501-6-4': {'ID': 811,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 4},\n",
        " 'increase-501-6-5': {'ID': 812,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 5},\n",
        " 'increase-501-6-6': {'ID': 813,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 6},\n",
        " 'increase-501-6-7': {'ID': 814,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 6,\n",
        "  'shift': 7},\n",
        " 'increase-501-7-1': {'ID': 817,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 1},\n",
        " 'increase-501-7-14': {'ID': 824,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 14},\n",
        " 'increase-501-7-2': {'ID': 818,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 2},\n",
        " 'increase-501-7-21': {'ID': 825,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 21},\n",
        " 'increase-501-7-3': {'ID': 819,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 3},\n",
        " 'increase-501-7-4': {'ID': 820,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 4},\n",
        " 'increase-501-7-5': {'ID': 821,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 5},\n",
        " 'increase-501-7-6': {'ID': 822,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 6},\n",
        " 'increase-501-7-7': {'ID': 823,\n",
        "  'analyze': 501,\n",
        "  'condition': 'increase',\n",
        "  'delta': 7,\n",
        "  'shift': 7}}"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test.allPointSelectionIds\n",
      "\n",
      "print test.allConditionIds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[300]\n",
        "[700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from SecNeural import nn\n",
      "\n",
      "\n",
      "mynet = nn.searchnet('hx0_Basic.db')\n",
      "results = mynet.getresult(test.allPointSelectionIds,test.allConditionIds)\n",
      "\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "{700: 5.808843478391672e-05,\n",
        " 701: 9.103077913493837e-05,\n",
        " 702: 0.00013617779371593398,\n",
        " 703: 0.0005189249151211695,\n",
        " 704: 0.0011007267824873147,\n",
        " 705: 0.0019291568610005996,\n",
        " 706: 0.0020196075507779685,\n",
        " 707: 0.0027283681845566574,\n",
        " 708: 0.0022792077261355333,\n",
        " 709: 0.0013135925947854417,\n",
        " 710: 0.0010957446740613233,\n",
        " 711: 0.001074928518634031,\n",
        " 712: 0.0010282778623403543,\n",
        " 713: 0.0009777622922643064,\n",
        " 714: 0.0009248492653986683,\n",
        " 715: 0.0008710122782880223,\n",
        " 716: 0.0008172839867342367,\n",
        " 717: 0.0005742475050510542,\n",
        " 718: 0.0005453995617835536,\n",
        " 719: 0.0005100658121617948,\n",
        " 720: 0.000476887957570232,\n",
        " 721: 0.00044587807614492915,\n",
        " 722: 0.0004170905184619091,\n",
        " 723: 0.0003903018444852423,\n",
        " 724: 0.00036548185975449434,\n",
        " 725: 0.00025746359046072793,\n",
        " 726: 0.0002468169635631728,\n",
        " 727: 0.00023374268825533648,\n",
        " 728: 0.00022167691355844005,\n",
        " 729: 0.00021063171734529853,\n",
        " 730: 0.00020047424325366964,\n",
        " 731: 0.00014373852965587837,\n",
        " 732: 0.00014114179127575774,\n",
        " 733: 0.00010303012615202891,\n",
        " 734: 7.779949107527244e-05,\n",
        " 735: 0.00010599523907431036,\n",
        " 736: 0.00010461836382753252,\n",
        " 737: 0.00010356759061261912,\n",
        " 738: 0.00010261947914839175,\n",
        " 739: 7.654339435246477e-05,\n",
        " 740: 7.883818644202429e-05,\n",
        " 741: 6.019602015572989e-05,\n",
        " 742: 4.793096029165673e-05,\n",
        " 743: 3.939191811266062e-05,\n",
        " 744: 5.8861417384528027e-05,\n",
        " 745: 6.166347931114758e-05,\n",
        " 746: 6.433872377897842e-05,\n",
        " 747: 5.025594702240326e-05,\n",
        " 748: 5.448319562235105e-05,\n",
        " 749: 5.779252738210178e-05,\n",
        " 750: 4.57569467247751e-05,\n",
        " 751: 2.8050813993555066e-05,\n",
        " 752: 2.684302867688005e-05,\n",
        " 753: 4.345611569935469e-05,\n",
        " 754: 3.58531071371492e-05,\n",
        " 755: 3.097365445956305e-05,\n",
        " 756: 2.757977772006135e-05,\n",
        " 757: 2.521855742582929e-05,\n",
        " 758: 2.3575969394891728e-05,\n",
        " 759: 2.2428573343793167e-05,\n",
        " 760: 2.1625396107988858e-05,\n",
        " 761: 2.106981486215295e-05,\n",
        " 762: 3.637849374961339e-05,\n",
        " 763: 4.119755715951799e-05,\n",
        " 764: 3.436149227177042e-05,\n",
        " 765: 2.9934959087403363e-05,\n",
        " 766: 2.6849067603463622e-05,\n",
        " 767: 2.4711287592759744e-05,\n",
        " 768: 2.3219672726399207e-05,\n",
        " 769: 2.2174938427226462e-05,\n",
        " 770: 3.7725174376871716e-05,\n",
        " 771: 5.621032862120654e-05}"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sortedResults = sorted(pairedResults, key=pairedResults.get, reverse=True)\n",
      "sortedConditions = []\n",
      "for _id in sortedResults:\n",
      "    sortedConditions.append(test.idLookupCondtion[_id])\n",
      "    \n",
      "sortedConditions\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "['increase-500-2-14',\n",
        " 'increase-500-2-21',\n",
        " 'increase-500-2-7',\n",
        " 'increase-500-2-6',\n",
        " 'increase-500-3-1',\n",
        " 'increase-500-2-5',\n",
        " 'increase-500-3-2',\n",
        " 'increase-500-3-3',\n",
        " 'increase-500-3-4',\n",
        " 'increase-500-3-5',\n",
        " 'increase-500-3-6',\n",
        " 'increase-500-3-7',\n",
        " 'increase-500-3-14',\n",
        " 'increase-500-3-21',\n",
        " 'increase-500-4-1',\n",
        " 'increase-500-2-4',\n",
        " 'increase-500-4-2',\n",
        " 'increase-500-4-3',\n",
        " 'increase-500-4-4',\n",
        " 'increase-500-4-5',\n",
        " 'increase-500-4-6',\n",
        " 'increase-500-4-7',\n",
        " 'increase-500-4-14',\n",
        " 'increase-500-4-21',\n",
        " 'increase-500-5-1',\n",
        " 'increase-500-5-2',\n",
        " 'increase-500-5-3',\n",
        " 'increase-500-5-4',\n",
        " 'increase-500-5-5',\n",
        " 'increase-500-5-6',\n",
        " 'increase-500-2-3',\n",
        " 'increase-500-5-21',\n",
        " 'increase-500-6-1',\n",
        " 'increase-500-6-2',\n",
        " 'increase-500-5-7',\n",
        " 'increase-500-6-3',\n",
        " 'increase-500-2-2',\n",
        " 'increase-500-6-5',\n",
        " 'increase-500-5-14',\n",
        " 'increase-500-6-4',\n",
        " 'increase-500-7-2',\n",
        " 'increase-500-7-1',\n",
        " 'increase-500-6-6',\n",
        " 'increase-500-6-21',\n",
        " 'increase-500-2-1',\n",
        " 'increase-500-7-5',\n",
        " 'increase-500-21-21',\n",
        " 'increase-500-7-4',\n",
        " 'increase-500-7-3',\n",
        " 'increase-500-6-7',\n",
        " 'increase-500-7-6',\n",
        " 'increase-500-7-21',\n",
        " 'increase-500-21-1',\n",
        " 'increase-500-6-14',\n",
        " 'increase-500-21-14',\n",
        " 'increase-500-14-21',\n",
        " 'increase-500-14-1',\n",
        " 'increase-500-21-2',\n",
        " 'increase-500-14-2',\n",
        " 'increase-500-21-3',\n",
        " 'increase-500-7-7',\n",
        " 'increase-500-14-3',\n",
        " 'increase-500-21-4',\n",
        " 'increase-500-7-14',\n",
        " 'increase-500-14-4',\n",
        " 'increase-500-21-5',\n",
        " 'increase-500-14-5',\n",
        " 'increase-500-21-6',\n",
        " 'increase-500-14-6',\n",
        " 'increase-500-21-7',\n",
        " 'increase-500-14-7',\n",
        " 'increase-500-14-14']"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NeuroResolve:\n",
      "    def __init__(self):\n",
      "        self.mynet = nn.searchnet('hx0_Basic.db')\n",
      "        self.getNeuralData()\n",
      "        \n",
      "    def getNeuralData(self):\n",
      "        self.mynet.getresult(test.allPointSelectionIds,test.allConditionIds)\n",
      "        \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "os.unlink('hx0_Basic.db')\n",
      "os.remove('hx0_Basic.db')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "WindowsError",
       "evalue": "[Error 32] The process cannot access the file because it is being used by another process: 'hx0_Basic.db'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mWindowsError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-10-7f4e30461d2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hx0_Basic.db'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hx0_Basic.db'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mWindowsError\u001b[0m: [Error 32] The process cannot access the file because it is being used by another process: 'hx0_Basic.db'"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "from SecApp.DBQuestionClass import SecuQ\n",
      "class NeuroDataComparative:\n",
      "    '''\n",
      "    REQUIRES NoSQL DATABASE ACCESS KEY\n",
      "    Establishes IDs for all data needing to be examined. \n",
      "    \n",
      "    For use in comparing many variables against one dependant\n",
      "    \n",
      "    conditions:\n",
      "    only one dependant variable\n",
      "    \n",
      "    as many independants as you'd like (must be list)\n",
      "    '''\n",
      "    \n",
      "    def __init__(self,key,depVar,indepVarsLst):\n",
      "        self.key = key\n",
      "        initQ = SecuQ(self.key)\n",
      "        \n",
      "        self.variable_v2id_dict = {}\n",
      "        self.variable_id2v_dict = {}\n",
      "        self.variable_lst = []\n",
      "        self.variableids_lst = []\n",
      "        \n",
      "        \n",
      "        self.independantVars = sorted(indepVarsLst, key=str.lower)\n",
      "        self.dependantVar = depVar\n",
      "        self.varTypes_v2t_dict = {}\n",
      "        self.varTypes_id2t_dict = {}\n",
      "        # data IDs start at 900, 900 is reserved for dependant variable, others are after that\n",
      "        \n",
      "        \n",
      "        #class main loop\n",
      "        self.iterateVariables()\n",
      "        \n",
      "        \n",
      "        \n",
      "    def genVariableids(self,varkey):\n",
      "            \n",
      "        self.variable_v2id_dict[varkey] = idcounter\n",
      "        self.variable_id2v_dict[idcounter] = varkey\n",
      "        self.variable_lst.append(varkey)\n",
      "        self.variableids_lst.append(idcounter)\n",
      "        self.idcounter +=1\n",
      "        return self\n",
      "    \n",
      "    #This determines the timedelta or normalization technique\n",
      "    def getanalyticstype(self,varkey): \n",
      "        if (varkey in initQ.multipoint.keys()) & (varkey in initQ.aggregate.keys()):\n",
      "            #self.varTypes_v2t_dict[varkey] = 'mp_aggre' # multipoint with aggregate data in dailykey, \"keyname\"_aggregate:value\n",
      "            \n",
      "            #self.varTypes_id2t_dict[self.variable_v2id_dict[varkey]] = 'mp_aggre'\n",
      "            raise Exception(\"NO MULTI-AGREGATE VARIABLES (IN ALPHA)\")\n",
      "            return False #breakloop\n",
      "            \n",
      "        if (varkey in initQ.aggregate.keys()):\n",
      "            self.varTypes_v2t_dict[varkey] = 'aggregate' # aggregate data in dailykey\n",
      "            self.varTypes_id2t_dict[self.variable_v2id_dict[varkey]] = 'aggregate'\n",
      "            return self #breakloop \n",
      "        \n",
      "        if (varkey in initQ.multipoint.keys()):\n",
      "            self.varTypes_v2t_dict[varkey] = 'multipoint'\n",
      "            self.varTypes_id2t_dict[self.variable_v2id_dict[varkey]] = 'multipoint'\n",
      "            return self #breakloop\n",
      "            \n",
      "        if (varkey in initQ.active.keys()):\n",
      "            self.varTypes_v2t_dict[varkey] = 'daily' # data in dailykey\n",
      "            self.varTypes_id2t_dict[self.variable_v2id_dict[varkey]] = 'daily'\n",
      "            return self #breakloop\n",
      "\n",
      "        \n",
      "    def iterateVariables(self):\n",
      "        #dependant first\n",
      "        self.idcounter = 900\n",
      "        self.genVariableids(self.dependantVar)\n",
      "        self.getanalyticstype(self.dependantVar)\n",
      "        \n",
      "        #independants in alphabetical order\n",
      "        for var in self.independantVars:\n",
      "            self.genVariableids(var)\n",
      "            self.getanalyticstype(var)\n",
      "            \n",
      "        return self\n",
      "        \n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}